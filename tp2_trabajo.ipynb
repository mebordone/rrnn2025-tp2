{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP2: Clasificación de Fashion-MNIST con PyTorch\n",
        "\n",
        "## Trabajo Práctico 2 - Redes Neuronales 2025\n",
        "\n",
        "### Referencias:\n",
        "- https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
        "- https://github.com/zalandoresearch/fashion-mnist\n",
        "- https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 1: Importación de Librerías\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías estándar de Python\n",
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "from collections import defaultdict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías third party de Python\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.linalg as linalg\n",
        "import sklearn as skl\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías de PyTorch\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "\n",
        "# Crear directorio de imágenes si no existe\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "# Función helper para escribir resultados en markdown\n",
        "results_file = 'resultados_experimentos.md'\n",
        "\n",
        "def init_results_file():\n",
        "    \"\"\"Inicializa el archivo de resultados\"\"\"\n",
        "    with open(results_file, 'w', encoding='utf-8') as f:\n",
        "        f.write('# Resultados de Experimentos - TP2 Fashion-MNIST\\n\\n')\n",
        "        f.write(f'**Fecha de ejecución**: {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n\\n')\n",
        "        f.write('---\\n\\n')\n",
        "        f.write('## Tabla de Contenidos\\n\\n')\n",
        "        f.write('1. [Configuración del Entorno](#configuración-del-entorno)\\n')\n",
        "        f.write('2. [Dataset Fashion-MNIST](#dataset-fashion-mnist)\\n')\n",
        "        f.write('3. [Entrenamiento Básico](#entrenamiento-básico)\\n')\n",
        "        f.write('4. [Análisis de Hiperparámetros](#análisis-de-hiperparámetros)\\n')\n",
        "        f.write('5. [Modelo Final](#modelo-final)\\n\\n')\n",
        "        f.write('---\\n\\n')\n",
        "\n",
        "def write_section(title, level=2):\n",
        "    \"\"\"Escribe una sección en el archivo de resultados\"\"\"\n",
        "    with open(results_file, 'a', encoding='utf-8') as f:\n",
        "        f.write(f'\\n{\"#\" * level} {title}\\n\\n')\n",
        "\n",
        "def write_text(text):\n",
        "    \"\"\"Escribe texto en el archivo de resultados\"\"\"\n",
        "    with open(results_file, 'a', encoding='utf-8') as f:\n",
        "        f.write(f'{text}\\n')\n",
        "\n",
        "def write_table(headers, rows):\n",
        "    \"\"\"Escribe una tabla en markdown\"\"\"\n",
        "    with open(results_file, 'a', encoding='utf-8') as f:\n",
        "        # Headers\n",
        "        f.write('| ' + ' | '.join(headers) + ' |\\n')\n",
        "        f.write('| ' + ' | '.join(['---'] * len(headers)) + ' |\\n')\n",
        "        # Rows\n",
        "        for row in rows:\n",
        "            f.write('| ' + ' | '.join(str(cell) for cell in row) + ' |\\n')\n",
        "        f.write('\\n')\n",
        "\n",
        "def write_image(image_path, caption=None):\n",
        "    \"\"\"Escribe referencia a imagen en markdown\"\"\"\n",
        "    with open(results_file, 'a', encoding='utf-8') as f:\n",
        "        if caption:\n",
        "            f.write(f'**{caption}**\\n\\n')\n",
        "        f.write(f'![{caption or \"Imagen\"}]({image_path})\\n\\n')\n",
        "\n",
        "# Inicializar archivo de resultados\n",
        "init_results_file()\n",
        "print(f'Archivo de resultados inicializado: {results_file}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 2: Configuración del Dispositivo (CPU/GPU)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detectar y configurar dispositivo\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Dispositivo utilizado: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'CUDA Version: {torch.version.cuda}')\n",
        "\n",
        "# Documentar configuración\n",
        "write_section('Configuración del Entorno', 2)\n",
        "write_text(f'- **Dispositivo**: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    write_text(f'- **GPU**: {torch.cuda.get_device_name(0)}')\n",
        "    write_text(f'- **CUDA Version**: {torch.version.cuda}')\n",
        "write_text(f'- **PyTorch Version**: {torch.__version__}')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 3: Carga y Exploración del Dataset Fashion-MNIST\n",
        "\n",
        "### 3.1: Descargar y cargar el dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normaliza de [0,1] a [-1,1]\n",
        "])\n",
        "\n",
        "# Download and load the training data\n",
        "train_set = datasets.FashionMNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "valid_set = datasets.FashionMNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2: Explorar el dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspeccionar tamaño de los conjuntos\n",
        "print(f'Tamaño del conjunto de entrenamiento: {len(train_set)}')\n",
        "print(f'Tamaño del conjunto de validación: {len(valid_set)}')\n",
        "\n",
        "# Ver un ejemplo\n",
        "image, label = train_set[0]\n",
        "print(f'\\nDimensiones de la imagen: {image.shape}')\n",
        "print(f'Etiqueta: {label}')\n",
        "print(f'Tipo de datos: {type(image)}')\n",
        "\n",
        "# Documentar dataset\n",
        "write_section('Dataset Fashion-MNIST', 2)\n",
        "write_text(f'- **Tamaño conjunto de entrenamiento**: {len(train_set)}')\n",
        "write_text(f'- **Tamaño conjunto de validación**: {len(valid_set)}')\n",
        "write_text(f'- **Dimensiones de imagen**: {image.shape}')\n",
        "write_text(f'- **Número de clases**: 10')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diccionario de nombres de clases (según paper original)\n",
        "class_names = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boots'\n",
        "}\n",
        "\n",
        "print('Clases de Fashion-MNIST:')\n",
        "for idx, name in class_names.items():\n",
        "    print(f'  {idx}: {name}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3: Visualización inicial - Mosaico de imágenes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear mosaico 3x3 de imágenes aleatorias\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "    j = torch.randint(len(train_set), size=(1,)).item()\n",
        "    image, label = train_set[j]\n",
        "    \n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(f'{class_names[label]} ({label})')\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image.squeeze(), cmap=\"Greys_r\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/fashion_mnist_ejemplos.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar visualización\n",
        "write_image('images/fashion_mnist_ejemplos.png', 'Mosaico 3x3 de ejemplos del dataset Fashion-MNIST')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 4: Definición de la Arquitectura de la Red Neuronal\n",
        "\n",
        "### 4.1: Crear DataLoaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear DataLoaders\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=100, shuffle=True)\n",
        "\n",
        "# Explorar un batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f'Dimensiones del batch de imágenes: {images.shape}')\n",
        "print(f'Dimensiones del batch de etiquetas: {labels.shape}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2: Definir la arquitectura de la red\n",
        "\n",
        "Arquitectura:\n",
        "- Capa de entrada: Flatten de 28×28 = 784 neuronas\n",
        "- Capa oculta 1: 128 neuronas + ReLU + Dropout(0.2)\n",
        "- Capa oculta 2: 64 neuronas + ReLU + Dropout(0.2)\n",
        "- Capa de salida: 10 neuronas (sin activación, CrossEntropyLoss aplica softmax)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la red neuronal\n",
        "class FashionMNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionMNIST_Net, self).__init__()\n",
        "        # Capa de entrada: 28x28 = 784\n",
        "        self.flatten = nn.Flatten()\n",
        "        \n",
        "        # Capas ocultas\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        \n",
        "        # Capa de salida\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3: Verificar la arquitectura\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear instancia del modelo y verificar\n",
        "model = FashionMNIST_Net()\n",
        "model.to(device)\n",
        "\n",
        "# Probar con un batch de ejemplo\n",
        "test_images, _ = next(iter(train_loader))\n",
        "test_images = test_images.to(device)\n",
        "output = model(test_images)\n",
        "\n",
        "print(f'Dimensiones de entrada: {test_images.shape}')\n",
        "print(f'Dimensiones de salida: {output.shape}')\n",
        "print(f'Modelo en dispositivo: {next(model.parameters()).device}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 5: Funciones de Entrenamiento y Validación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Entrena el modelo por una época.\n",
        "    \n",
        "    Returns:\n",
        "        train_loss: pérdida promedio de la época\n",
        "        train_acc: precisión promedio de la época\n",
        "    \"\"\"\n",
        "    model.train()  # Modo entrenamiento\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for images, labels in train_loader:\n",
        "        # Mover datos al dispositivo\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Calcular métricas\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    \n",
        "    return train_loss, train_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, valid_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evalúa el modelo sobre el conjunto de validación.\n",
        "    \n",
        "    Returns:\n",
        "        val_loss: pérdida promedio\n",
        "        val_acc: precisión promedio\n",
        "    \"\"\"\n",
        "    model.eval()  # Modo evaluación\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            # Mover datos al dispositivo\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Calcular métricas\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    val_loss = running_loss / len(valid_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    \n",
        "    return val_loss, val_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 6: Entrenamiento Básico\n",
        "\n",
        "### 6.1: Configurar entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función de pérdida\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Reinicializar modelo\n",
        "model = FashionMNIST_Net()\n",
        "model.to(device)\n",
        "\n",
        "# Optimizador (debe crearse DESPUÉS de reinicializar el modelo)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(f'Modelo configurado en: {device}')\n",
        "print(f'Learning rate: {learning_rate}')\n",
        "print(f'Optimizador: SGD')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2: Loop principal de entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar listas para guardar métricas\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Número de épocas\n",
        "num_epochs = 30\n",
        "\n",
        "print(f'Iniciando entrenamiento por {num_epochs} épocas...')\n",
        "print('-' * 60)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Entrenar\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Validar\n",
        "    val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "    \n",
        "    # Guardar métricas\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    # Imprimir progreso\n",
        "    print(f'Época [{epoch+1}/{num_epochs}]')\n",
        "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print('-' * 60)\n",
        "\n",
        "print('Entrenamiento completado!')\n",
        "\n",
        "# Documentar entrenamiento básico\n",
        "write_section('Entrenamiento Básico', 2)\n",
        "write_text('### Configuración')\n",
        "write_text(f'- **Optimizador**: SGD')\n",
        "write_text(f'- **Learning Rate**: {learning_rate}')\n",
        "write_text(f'- **Batch Size**: 100')\n",
        "write_text(f'- **Épocas**: {num_epochs}')\n",
        "write_text(f'- **Dropout**: 0.2')\n",
        "write_text('')\n",
        "write_text('### Resultados Finales')\n",
        "write_text(f'- **Train Accuracy**: {train_accuracies[-1]:.2f}%')\n",
        "write_text(f'- **Validation Accuracy**: {val_accuracies[-1]:.2f}%')\n",
        "write_text(f'- **Train Loss**: {train_losses[-1]:.4f}')\n",
        "write_text(f'- **Validation Loss**: {val_losses[-1]:.4f}')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 7: Visualización de Resultados Básicos\n",
        "\n",
        "### 7.1: Gráficos de curvas de entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear figura con curvas de entrenamiento\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Gráfico de pérdida\n",
        "ax1.plot(train_losses, label='Train Loss', marker='o')\n",
        "ax1.plot(val_losses, label='Validation Loss', marker='s')\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Cross Entropy Loss')\n",
        "ax1.set_title('Pérdida durante el Entrenamiento')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico de precisión\n",
        "ax2.plot(train_accuracies, label='Train Accuracy', marker='o')\n",
        "ax2.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Precisión (%)')\n",
        "ax2.set_title('Precisión durante el Entrenamiento')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/curvas_entrenamiento_basico.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar visualización\n",
        "write_image('images/curvas_entrenamiento_basico.png', 'Curvas de entrenamiento básico')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2: Matriz de confusión\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener todas las predicciones del conjunto de validación\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in valid_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calcular matriz de confusión\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=[class_names[i] for i in range(10)],\n",
        "            yticklabels=[class_names[i] for i in range(10)])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusión - Fashion-MNIST')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/matriz_confusion_basico.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Calcular precisión general\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f'Precisión general en validación: {accuracy*100:.2f}%')\n",
        "\n",
        "# Documentar matriz de confusión\n",
        "write_image('images/matriz_confusion_basico.png', 'Matriz de confusión - Entrenamiento básico')\n",
        "write_text(f'**Precisión general en validación**: {accuracy*100:.2f}%')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 8: Análisis de Hiperparámetros\n",
        "\n",
        "Esta sección contiene experimentos para analizar el efecto de diferentes hiperparámetros en el rendimiento del modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1: Variar Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar diferentes learning rates\n",
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "results_lr = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f'\\nEntrenando con learning rate = {lr}...')\n",
        "    \n",
        "    # Reinicializar modelo\n",
        "    model = FashionMNIST_Net()\n",
        "    model.to(device)\n",
        "    \n",
        "    # Configurar optimizador\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_lr = []\n",
        "    val_losses_lr = []\n",
        "    train_accs_lr = []\n",
        "    val_accs_lr = []\n",
        "    \n",
        "    # Entrenar por 10 épocas\n",
        "    for epoch in range(10):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "        \n",
        "        train_losses_lr.append(train_loss)\n",
        "        val_losses_lr.append(val_loss)\n",
        "        train_accs_lr.append(train_acc)\n",
        "        val_accs_lr.append(val_acc)\n",
        "    \n",
        "    results_lr[lr] = {\n",
        "        'train_losses': train_losses_lr,\n",
        "        'val_losses': val_losses_lr,\n",
        "        'train_accs': train_accs_lr,\n",
        "        'val_accs': val_accs_lr\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "# Visualizar comparación\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for lr in learning_rates:\n",
        "    ax1.plot(results_lr[lr]['val_losses'], label=f'LR={lr}', marker='o')\n",
        "    ax2.plot(results_lr[lr]['val_accs'], label=f'LR={lr}', marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Learning Rates - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Learning Rates - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_learning_rates.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Análisis de Hiperparámetros', 2)\n",
        "write_section('Experimento 1: Variar Learning Rate', 3)\n",
        "write_text('**Valores probados**: 0.0001, 0.001, 0.01')\n",
        "write_text('**Configuración**: SGD, Batch Size=100, Épocas=10, Dropout=0.2')\n",
        "write_text('')\n",
        "headers = ['Learning Rate', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[lr, f'{results_lr[lr][\"train_accs\"][-1]:.2f}%', f'{results_lr[lr][\"val_accs\"][-1]:.2f}%'] for lr in learning_rates]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_learning_rates.png', 'Comparación de Learning Rates')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2: Comparar Optimizadores (SGD vs ADAM)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar SGD vs ADAM\n",
        "optimizers_config = {\n",
        "    'SGD': torch.optim.SGD,\n",
        "    'ADAM': torch.optim.Adam\n",
        "}\n",
        "\n",
        "results_opt = {}\n",
        "\n",
        "for opt_name, opt_class in optimizers_config.items():\n",
        "    print(f'\\nEntrenando con {opt_name}...')\n",
        "    \n",
        "    # Reinicializar modelo\n",
        "    model = FashionMNIST_Net()\n",
        "    model.to(device)\n",
        "    \n",
        "    # Configurar optimizador\n",
        "    optimizer = opt_class(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_opt = []\n",
        "    val_losses_opt = []\n",
        "    train_accs_opt = []\n",
        "    val_accs_opt = []\n",
        "    \n",
        "    # Entrenar por 10 épocas\n",
        "    for epoch in range(10):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "        \n",
        "        train_losses_opt.append(train_loss)\n",
        "        val_losses_opt.append(val_loss)\n",
        "        train_accs_opt.append(train_acc)\n",
        "        val_accs_opt.append(val_acc)\n",
        "    \n",
        "    results_opt[opt_name] = {\n",
        "        'train_losses': train_losses_opt,\n",
        "        'val_losses': val_losses_opt,\n",
        "        'train_accs': train_accs_opt,\n",
        "        'val_accs': val_accs_opt\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "# Visualizar comparación\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for opt_name in optimizers_config.keys():\n",
        "    ax1.plot(results_opt[opt_name]['val_losses'], label=opt_name, marker='o')\n",
        "    ax2.plot(results_opt[opt_name]['val_accs'], label=opt_name, marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Optimizadores - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Optimizadores - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_optimizadores.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Experimento 2: Comparar Optimizadores (SGD vs ADAM)', 3)\n",
        "write_text('**Optimizadores probados**: SGD, ADAM')\n",
        "write_text('**Configuración**: LR=0.001, Batch Size=100, Épocas=10, Dropout=0.2')\n",
        "write_text('')\n",
        "headers = ['Optimizador', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[opt, f'{results_opt[opt][\"train_accs\"][-1]:.2f}%', f'{results_opt[opt][\"val_accs\"][-1]:.2f}%'] for opt in optimizers_config.keys()]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_optimizadores.png', 'Comparación de Optimizadores')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3: Variar valor de Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir una función para crear modelos con diferentes valores de dropout\n",
        "def create_model_with_dropout(dropout_rate):\n",
        "    \"\"\"Crea un modelo con un valor específico de dropout\"\"\"\n",
        "    class FashionMNIST_Net_Dropout(nn.Module):\n",
        "        def __init__(self, dropout_rate=0.2):\n",
        "            super(FashionMNIST_Net_Dropout, self).__init__()\n",
        "            self.flatten = nn.Flatten()\n",
        "            self.fc1 = nn.Linear(784, 128)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.dropout1 = nn.Dropout(dropout_rate)\n",
        "            self.fc2 = nn.Linear(128, 64)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.dropout2 = nn.Dropout(dropout_rate)\n",
        "            self.fc3 = nn.Linear(64, 10)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            x = self.flatten(x)\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.dropout1(x)\n",
        "            x = self.fc2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.dropout2(x)\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "    \n",
        "    return FashionMNIST_Net_Dropout(dropout_rate)\n",
        "\n",
        "# Probar diferentes valores de dropout\n",
        "dropout_values = [0.0, 0.2, 0.4, 0.6]\n",
        "results_dropout = {}\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    print(f'\\nEntrenando con dropout = {dropout_rate}...')\n",
        "    \n",
        "    # Crear modelo con el valor de dropout específico\n",
        "    model = create_model_with_dropout(dropout_rate)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Configurar optimizador\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_dropout = []\n",
        "    val_losses_dropout = []\n",
        "    train_accs_dropout = []\n",
        "    val_accs_dropout = []\n",
        "    \n",
        "    # Entrenar por 10 épocas\n",
        "    for epoch in range(10):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "        \n",
        "        train_losses_dropout.append(train_loss)\n",
        "        val_losses_dropout.append(val_loss)\n",
        "        train_accs_dropout.append(train_acc)\n",
        "        val_accs_dropout.append(val_acc)\n",
        "    \n",
        "    results_dropout[dropout_rate] = {\n",
        "        'train_losses': train_losses_dropout,\n",
        "        'val_losses': val_losses_dropout,\n",
        "        'train_accs': train_accs_dropout,\n",
        "        'val_accs': val_accs_dropout\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_accs_dropout[-1]:.2f}%, Val Acc: {val_accs_dropout[-1]:.2f}%')\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    ax1.plot(results_dropout[dropout_rate]['val_losses'], \n",
        "             label=f'Dropout={dropout_rate}', marker='o')\n",
        "    ax2.plot(results_dropout[dropout_rate]['val_accs'], \n",
        "             label=f'Dropout={dropout_rate}', marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Dropout - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Dropout - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_dropout.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Experimento 3: Variar Dropout', 3)\n",
        "write_text('**Valores probados**: 0.0, 0.2, 0.4, 0.6')\n",
        "write_text('**Configuración**: SGD, LR=0.001, Batch Size=100, Épocas=10')\n",
        "write_text('')\n",
        "headers = ['Dropout', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[dr, f'{results_dropout[dr][\"train_accs\"][-1]:.2f}%', f'{results_dropout[dr][\"val_accs\"][-1]:.2f}%'] for dr in dropout_values]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_dropout.png', 'Comparación de Dropout')\n",
        "write_text('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4: Variar número de neuronas en las capas intermedias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir función para crear modelos con diferentes arquitecturas\n",
        "def create_model_with_neurons(n1, n2):\n",
        "    \"\"\"Crea un modelo con n1 y n2 neuronas en las capas ocultas\"\"\"\n",
        "    class FashionMNIST_Net_Neurons(nn.Module):\n",
        "        def __init__(self, n1=128, n2=64):\n",
        "            super(FashionMNIST_Net_Neurons, self).__init__()\n",
        "            self.flatten = nn.Flatten()\n",
        "            self.fc1 = nn.Linear(784, n1)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.dropout1 = nn.Dropout(0.2)\n",
        "            self.fc2 = nn.Linear(n1, n2)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.dropout2 = nn.Dropout(0.2)\n",
        "            self.fc3 = nn.Linear(n2, 10)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            x = self.flatten(x)\n",
        "            x = self.fc1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.dropout1(x)\n",
        "            x = self.fc2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.dropout2(x)\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "    \n",
        "    return FashionMNIST_Net_Neurons(n1, n2)\n",
        "\n",
        "# Probar diferentes configuraciones de neuronas\n",
        "neuron_configs = [\n",
        "    (64, 32),   # Más pequeña\n",
        "    (128, 64),  # Original\n",
        "    (256, 128), # Más grande\n",
        "    (512, 256)  # Mucho más grande\n",
        "]\n",
        "\n",
        "results_neurons = {}\n",
        "\n",
        "for n1, n2 in neuron_configs:\n",
        "    config_name = f'{n1}-{n2}'\n",
        "    print(f'\\nEntrenando con arquitectura {n1}-{n2}...')\n",
        "    \n",
        "    # Crear modelo\n",
        "    model = create_model_with_neurons(n1, n2)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Configurar optimizador\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_neurons = []\n",
        "    val_losses_neurons = []\n",
        "    train_accs_neurons = []\n",
        "    val_accs_neurons = []\n",
        "    \n",
        "    # Entrenar por 10 épocas\n",
        "    for epoch in range(10):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "        \n",
        "        train_losses_neurons.append(train_loss)\n",
        "        val_losses_neurons.append(val_loss)\n",
        "        train_accs_neurons.append(train_acc)\n",
        "        val_accs_neurons.append(val_acc)\n",
        "    \n",
        "    results_neurons[config_name] = {\n",
        "        'train_losses': train_losses_neurons,\n",
        "        'val_losses': val_losses_neurons,\n",
        "        'train_accs': train_accs_neurons,\n",
        "        'val_accs': val_accs_neurons\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_accs_neurons[-1]:.2f}%, Val Acc: {val_accs_neurons[-1]:.2f}%')\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for config_name in results_neurons.keys():\n",
        "    ax1.plot(results_neurons[config_name]['val_losses'], \n",
        "             label=f'{config_name}', marker='o')\n",
        "    ax2.plot(results_neurons[config_name]['val_accs'], \n",
        "             label=f'{config_name}', marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Arquitecturas - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Arquitecturas - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_neuronas.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Experimento 4: Variar Número de Neuronas', 3)\n",
        "write_text('**Configuraciones probadas**: (64,32), (128,64), (256,128), (512,256)')\n",
        "write_text('**Configuración**: SGD, LR=0.001, Batch Size=100, Épocas=10, Dropout=0.2')\n",
        "write_text('')\n",
        "headers = ['Arquitectura', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[config, f'{results_neurons[config][\"train_accs\"][-1]:.2f}%', f'{results_neurons[config][\"val_accs\"][-1]:.2f}%'] for config in results_neurons.keys()]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_neuronas.png', 'Comparación de Arquitecturas')\n",
        "write_text('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.5: Variar número de épocas de entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar el mismo modelo con diferentes números de épocas\n",
        "epochs_to_test = [5, 10, 15, 20, 30]\n",
        "results_epochs = {}\n",
        "\n",
        "for num_epochs in epochs_to_test:\n",
        "    print(f'\\nEntrenando por {num_epochs} épocas...')\n",
        "    \n",
        "    # Reinicializar modelo para cada experimento\n",
        "    model = FashionMNIST_Net()\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_epochs = []\n",
        "    val_losses_epochs = []\n",
        "    train_accs_epochs = []\n",
        "    val_accs_epochs = []\n",
        "    \n",
        "    # Entrenar\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
        "        \n",
        "        train_losses_epochs.append(train_loss)\n",
        "        val_losses_epochs.append(val_loss)\n",
        "        train_accs_epochs.append(train_acc)\n",
        "        val_accs_epochs.append(val_acc)\n",
        "    \n",
        "    results_epochs[num_epochs] = {\n",
        "        'train_losses': train_losses_epochs,\n",
        "        'val_losses': val_losses_epochs,\n",
        "        'train_accs': train_accs_epochs,\n",
        "        'val_accs': val_accs_epochs\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_accs_epochs[-1]:.2f}%, Val Acc: {val_accs_epochs[-1]:.2f}%')\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for num_epochs in epochs_to_test:\n",
        "    epochs_list = list(range(1, num_epochs + 1))\n",
        "    ax1.plot(epochs_list, results_epochs[num_epochs]['val_losses'], \n",
        "             label=f'{num_epochs} épocas', marker='o')\n",
        "    ax2.plot(epochs_list, results_epochs[num_epochs]['val_accs'], \n",
        "             label=f'{num_epochs} épocas', marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Épocas - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Épocas - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_epocas.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Experimento 5: Variar Número de Épocas', 3)\n",
        "write_text('**Valores probados**: 5, 10, 15, 20, 30')\n",
        "write_text('**Configuración**: SGD, LR=0.001, Batch Size=100, Dropout=0.2')\n",
        "write_text('')\n",
        "headers = ['Épocas', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[ep, f'{results_epochs[ep][\"train_accs\"][-1]:.2f}%', f'{results_epochs[ep][\"val_accs\"][-1]:.2f}%'] for ep in epochs_to_test]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_epocas.png', 'Comparación de Épocas')\n",
        "write_text('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.6: Variar tamaño de los lotes (batch size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Probar diferentes tamaños de batch\n",
        "batch_sizes = [32, 64, 100, 128, 256]\n",
        "results_batch = {}\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    print(f'\\nEntrenando con batch_size = {batch_size}...')\n",
        "    \n",
        "    # Crear nuevos DataLoaders con el batch_size específico\n",
        "    train_loader_batch = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    valid_loader_batch = torch.utils.data.DataLoader(\n",
        "        valid_set, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    \n",
        "    # Reinicializar modelo\n",
        "    model = FashionMNIST_Net()\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Listas para métricas\n",
        "    train_losses_batch = []\n",
        "    val_losses_batch = []\n",
        "    train_accs_batch = []\n",
        "    val_accs_batch = []\n",
        "    \n",
        "    # Entrenar por 10 épocas\n",
        "    for epoch in range(10):\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader_batch, criterion, optimizer, device\n",
        "        )\n",
        "        val_loss, val_acc = validate(\n",
        "            model, valid_loader_batch, criterion, device\n",
        "        )\n",
        "        \n",
        "        train_losses_batch.append(train_loss)\n",
        "        val_losses_batch.append(val_loss)\n",
        "        train_accs_batch.append(train_acc)\n",
        "        val_accs_batch.append(val_acc)\n",
        "    \n",
        "    results_batch[batch_size] = {\n",
        "        'train_losses': train_losses_batch,\n",
        "        'val_losses': val_losses_batch,\n",
        "        'train_accs': train_accs_batch,\n",
        "        'val_accs': val_accs_batch\n",
        "    }\n",
        "    \n",
        "    print(f'Final - Train Acc: {train_accs_batch[-1]:.2f}%, Val Acc: {val_accs_batch[-1]:.2f}%')\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    ax1.plot(results_batch[batch_size]['val_losses'], \n",
        "             label=f'Batch={batch_size}', marker='o')\n",
        "    ax2.plot(results_batch[batch_size]['val_accs'], \n",
        "             label=f'Batch={batch_size}', marker='o')\n",
        "\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Validation Loss')\n",
        "ax1.set_title('Comparación de Batch Size - Pérdida')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Validation Accuracy (%)')\n",
        "ax2.set_title('Comparación de Batch Size - Precisión')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/comparacion_batch_size.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar experimento\n",
        "write_section('Experimento 6: Variar Batch Size', 3)\n",
        "write_text('**Valores probados**: 32, 64, 100, 128, 256')\n",
        "write_text('**Configuración**: SGD, LR=0.001, Épocas=10, Dropout=0.2')\n",
        "write_text('')\n",
        "headers = ['Batch Size', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows = [[bs, f'{results_batch[bs][\"train_accs\"][-1]:.2f}%', f'{results_batch[bs][\"val_accs\"][-1]:.2f}%'] for bs in batch_sizes]\n",
        "write_table(headers, rows)\n",
        "write_image('images/comparacion_batch_size.png', 'Comparación de Batch Size')\n",
        "write_text('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sección 9: Generación de Figuras Finales\n",
        "\n",
        "### 9.1: Entrenar modelo final con mejores hiperparámetros\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleccionar mejores hiperparámetros basado en análisis previo\n",
        "# Resultados del análisis:\n",
        "# - ADAM: 88.06% validation accuracy (mejor que SGD: 73.44%)\n",
        "# - Learning Rate 0.001: óptimo con ADAM\n",
        "# - 30 épocas: mejor resultado (79.63%)\n",
        "# - Batch size 32: mejor resultado (79.35%)\n",
        "\n",
        "best_lr = 0.001  # Óptimo con ADAM\n",
        "best_optimizer = 'ADAM'  # Mejor rendimiento: 88.06% vs 73.44% de SGD\n",
        "optimal_epochs = 30  # Mejor resultado: 79.63% validation accuracy\n",
        "optimal_batch_size = 32  # Mejor resultado: 79.35% validation accuracy\n",
        "\n",
        "# Crear DataLoaders con batch size óptimo\n",
        "train_loader_optimal = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=optimal_batch_size, shuffle=True\n",
        ")\n",
        "valid_loader_optimal = torch.utils.data.DataLoader(\n",
        "    valid_set, batch_size=optimal_batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "# Reinicializar modelo\n",
        "model_final = FashionMNIST_Net()\n",
        "model_final.to(device)\n",
        "\n",
        "# Configurar optimizador final\n",
        "if best_optimizer == 'ADAM':\n",
        "    optimizer_final = torch.optim.Adam(model_final.parameters(), lr=best_lr)\n",
        "else:\n",
        "    optimizer_final = torch.optim.SGD(model_final.parameters(), lr=best_lr)\n",
        "\n",
        "# Listas para métricas finales\n",
        "train_losses_final = []\n",
        "train_accuracies_final = []\n",
        "val_losses_final = []\n",
        "val_accuracies_final = []\n",
        "\n",
        "print(f'Entrenando modelo final con configuración óptima:')\n",
        "print(f'  Optimizador: {best_optimizer}')\n",
        "print(f'  Learning Rate: {best_lr}')\n",
        "print(f'  Batch Size: {optimal_batch_size}')\n",
        "print(f'  Épocas: {optimal_epochs}')\n",
        "print('-' * 60)\n",
        "\n",
        "for epoch in range(optimal_epochs):\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model_final, train_loader_optimal, criterion, optimizer_final, device\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model_final, valid_loader_optimal, criterion, device\n",
        "    )\n",
        "    \n",
        "    train_losses_final.append(train_loss)\n",
        "    train_accuracies_final.append(train_acc)\n",
        "    val_losses_final.append(val_loss)\n",
        "    val_accuracies_final.append(val_acc)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Época [{epoch+1}/{optimal_epochs}] - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "print('\\nEntrenamiento final completado!')\n",
        "print(f'Precisión final en validación: {val_accuracies_final[-1]:.2f}%')\n",
        "\n",
        "# Documentar modelo final\n",
        "write_section('Modelo Final', 2)\n",
        "write_text('### Configuración Óptima Aplicada')\n",
        "write_text(f'- **Optimizador**: {best_optimizer}')\n",
        "write_text(f'- **Learning Rate**: {best_lr}')\n",
        "write_text(f'- **Batch Size**: {optimal_batch_size}')\n",
        "write_text(f'- **Épocas**: {optimal_epochs}')\n",
        "write_text(f'- **Dropout**: 0.2')\n",
        "write_text('')\n",
        "write_text('### Resultados del Entrenamiento')\n",
        "write_text('')\n",
        "write_text('**Progreso por Épocas:**')\n",
        "write_text('')\n",
        "headers_epochs = ['Época', 'Train Accuracy', 'Validation Accuracy']\n",
        "rows_epochs = []\n",
        "for i in range(0, optimal_epochs, 5):\n",
        "    if i < len(train_accuracies_final):\n",
        "        rows_epochs.append([i+1, f'{train_accuracies_final[i]:.2f}%', f'{val_accuracies_final[i]:.2f}%'])\n",
        "rows_epochs.append([optimal_epochs, f'{train_accuracies_final[-1]:.2f}%', f'{val_accuracies_final[-1]:.2f}%'])\n",
        "write_table(headers_epochs, rows_epochs)\n",
        "write_text('')\n",
        "write_text(f'**Resultado Final:**')\n",
        "write_text(f'- **Precisión en Validación**: {val_accuracies_final[-1]:.2f}%')\n",
        "write_text(f'- **Precisión en Entrenamiento**: {train_accuracies_final[-1]:.2f}%')\n",
        "write_text(f'- **Validation Loss**: {val_losses_final[-1]:.4f}')\n",
        "write_text(f'- **Train Loss**: {train_losses_final[-1]:.4f}')\n",
        "write_text('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2: Generar figuras finales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curvas de entrenamiento finales\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax1.plot(train_losses_final, label='Train Loss', marker='o')\n",
        "ax1.plot(val_losses_final, label='Validation Loss', marker='s')\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Cross Entropy Loss')\n",
        "ax1.set_title('Pérdida durante el Entrenamiento - Modelo Final')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.plot(train_accuracies_final, label='Train Accuracy', marker='o')\n",
        "ax2.plot(val_accuracies_final, label='Validation Accuracy', marker='s')\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Precisión (%)')\n",
        "ax2.set_title('Precisión durante el Entrenamiento - Modelo Final')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/curvas_entrenamiento_final.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Documentar visualización\n",
        "write_image('images/curvas_entrenamiento_final.png', 'Curvas de entrenamiento - Modelo Final')\n",
        "write_text('')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confusión final\n",
        "model_final.eval()\n",
        "all_preds_final = []\n",
        "all_labels_final = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in valid_loader_optimal:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model_final(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        all_preds_final.extend(predicted.cpu().numpy())\n",
        "        all_labels_final.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calcular matriz de confusión\n",
        "cm_final = confusion_matrix(all_labels_final, all_preds_final)\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=[class_names[i] for i in range(10)],\n",
        "            yticklabels=[class_names[i] for i in range(10)])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusión - Modelo Final')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/matriz_confusion_final.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Calcular precisión final\n",
        "accuracy_final = accuracy_score(all_labels_final, all_preds_final)\n",
        "print(f'Precisión final en validación: {accuracy_final*100:.2f}%')\n",
        "\n",
        "# Documentar matriz de confusión final\n",
        "write_image('images/matriz_confusion_final.png', 'Matriz de confusión - Modelo Final')\n",
        "write_text(f'**Precisión final en validación**: {accuracy_final*100:.2f}%')\n",
        "write_text('')\n",
        "write_text('---')\n",
        "write_text('')\n",
        "write_text(f'*Documento generado automáticamente el {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}*')\n",
        "print(f'\\n✅ Documento de resultados guardado en: {results_file}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
