{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendiendo Fashion-MNIST con PyTorch\n",
        "\n",
        "## Refs.\n",
        "\n",
        "* https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
        "\n",
        "* https://github.com/zalandoresearch/fashion-mnist\n",
        "\n",
        "* https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb\n",
        "\n",
        "## **Ejercicio 1)** Importando librerías\n",
        "\n",
        "**0)** De ser necesario, **instale PyTorch** escribiendo\n",
        "\n",
        "    !pip3 install torch torchvision torchaudio torchviz\n",
        "\n",
        "**1)** Importe las librerías estandard de Python: `os`, `datetime`, `collections` y `pickle`.\n",
        "\n",
        "**2)** Importe las siguientes librerías third party de Python: `matplotlib.pyplot`, `numpy`, `scipy`, `sklearn`, `pandas`, `dill` y `json`.\n",
        "\n",
        "**3)** Importe las librerias necesarias de **PyTorch**: `torch` y `torchvision`.\n",
        "\n",
        "**4)** Importe la librería: `google.colab`."
      ],
      "metadata": {
        "id": "NRYEofSD0xoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.0)\n",
        "!pip3 install torch torchvision torchaudio torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D79v2F3-s7vu",
        "outputId": "ff535901-d1c7-4a5a-8c11-d22d452985d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1)\n",
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "I8N3D_nU1_oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2)\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.linalg as linalg\n",
        "import sklearn as skl\n",
        "import pandas as pd\n",
        "#import dill\n",
        "import json"
      ],
      "metadata": {
        "id": "QsfFvPYhkCGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3)\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "#from torchviz import make_dot"
      ],
      "metadata": {
        "id": "Uot5sVNnkCNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4)\n",
        "import google.colab\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "rVCiYt-1kCUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 2)**\n",
        "\n",
        "Bajando y Jugando con el dataset **Fashion-MNIST**.\n",
        "\n",
        "**1)** Baje y transforme (i.e. normalize los valores de los pixeles) los conjuntos de entrenamiento y testeo de FashionMNIST.\n",
        "\n",
        "**2)** Explore algunos ejemplos de estos conjuntos. Que formato poseen?\n",
        "\n",
        "**3)** Visitando la página web de FashionMNIST, cree un diccionario de Python `Dict()` asociando cada categoría a un nombre adecuado de la misma.\n",
        "\n",
        "**4)** Grafique un mosaico de 3x3 imagenes de FashionMNIST, cada una titulada con su respectiva clasificación"
      ],
      "metadata": {
        "id": "NcaGEHAd10sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1)\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor()\n",
        "                                ,transforms.Normalize((0.5,), (0.5,))\n",
        "                                #,transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "\n",
        "# Download and load the training data\n",
        "train_set = datasets.FashionMNIST('MNIST_data/', download = True, train = True,  transform = transform)\n",
        "valid_set = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)"
      ],
      "metadata": {
        "id": "NUoQ9bnwaZ7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6389205-99a6-43d1-b620-e7de4f58808b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 15.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 270kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.00MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3)\n",
        "\n",
        "Creando un `DataLoader` para alimentar el modelo con batchs (lotes) de entrenamiento.\n",
        "\n",
        "**1)** Cree los `DataLoader`s para cada conjunto. Defínalos con un `batch_size` de 100 y con el flag `shuffle` seteado a `True`.\n",
        "\n",
        "**2)** Use uno de los `DataLoader`s creados anteriormente para explorar algunos elementos del conjunto.\n",
        "\n",
        "Notar que, el iterador devuelve el batch en un par `(image,label)`.\n",
        "\n",
        "El objeto `images` es un tensor de dimensiones `(100,1,28,28)`.\n",
        "El 100 es el tamaño del batch.\n",
        "El 1 porque hay un solo canal (en este caso, un canal de escala de grises, pero podría haber varios, p. ej. uno por cada color de {Red, Green Blue} en caso que fuesen imagenes a color).\n",
        "Luego, 28 y 28 porque cada imagen del dataset es de 28 x 28 píxeles.\n",
        "\n",
        "El objeto `labels` es un tensor de dimensiones `(100,)`.\n",
        "La $i$-ésima entrada `labels[i]` de `labels` es un número en $\\{0,1,...,9\\}$ indicando la categoría a la que pertenece la $i$-ésima imagen en el batch, guardada en `images[i]`."
      ],
      "metadata": {
        "id": "1OWYnfxWz8RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = 100, shuffle = True)"
      ],
      "metadata": {
        "id": "lK7gqh7lrTi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4)\n",
        "\n",
        "Defina una red neuronal de 4 capas, una de entrada, dos ocultas de $n_1=128$ y $n_2=64$ neuronas, respectivamente, y una de salida de 10 neuronas.\n",
        "\n",
        "En las capas intermedias utilice neuronas tipo ReLU y agregueles un *dropout* de p=0.2.\n",
        "En la capa de salida no utilice funciones de activación ni dropout.\n",
        "\n",
        "Las capas sucesivas tienen que estar totalmente conectadas entre si."
      ],
      "metadata": {
        "id": "REToccG127zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4)"
      ],
      "metadata": {
        "id": "C17Tib9G_k-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 5)\n",
        "\n",
        "Entrenamos el modelo\n",
        "\n",
        "**1)** Implemente, en una función, un loop de entrenamiento que recorra los batchs (lotes).\n",
        "\n",
        "**2)** Implemente, en una función, un loop de validación que recorra los batchs.\n",
        "\n",
        "**3)** Inicialize dos `DataLoader`s llamados `train_loader` y `valid_loader` a partir del `train_set` (conjunto de entranmiento) y del `valid_set` (conjunto de validación) de Fashion-MNIST, respectivamente, y que usen batchs de 100 ejemplos.\n",
        "\n",
        "**4)** Cree una función de pérdida usando la **Cross Entropy Loss**.\n",
        "\n",
        "**IMPORTANTE:** Notar que la **Cross Entropy Loss** aplica automáticamente una `log_softmax`.\n",
        "\n",
        "**5)** Cree un optimizador que utilice el método de **Stochastic Gradient Descent** con un learning rate igual a $10^{-3}$.\n",
        "\n",
        "**6)** Cree una instancia del modelo.\n",
        "\n",
        "**7)** Especifique en que dispositivo (`device`) va a trabajar: en una **CPU** o en una **GPU**.\n",
        "\n",
        "**8)** Implemente un loop de entrenamiento y validación que trabaje con el `train_loader` y el `valid_loader`, respectivamente, usando un numero arbitrario de épocas.\n",
        "Este loop debe guardar en cuatro listas los valores de los promedios del **Cross Entropy Loss** y las fracciones de clasificaciones correctas o **precisión** (accuracy) sobre el conjunto de **entrenamiento** y el de **validación**, respectivamente.\n",
        "\n",
        "**IMPORTANTE:** No olvide copiar los batchs al dispositivo de trabajo.\n",
        "\n",
        "**9)** Entrene y valide el modelo.\n",
        "\n",
        "**10)** Use las listas del inciso anterior para graficar en función de las épocas la **Cross Entropy Loss** de **entrenamiento** y de **validación**.\n",
        "Realize un gráfico análogo pero con la **precisión**.\n",
        "Discuta y comente, cual es el número óptimo de épocas de entrenamiento?\n",
        "\n",
        "**11)** Repita los experimentos variando hiperparámetros. Por ejemplo:\n",
        "\n",
        "- El learning-rate.\n",
        "- El optimizador (ej. puede usar ADAM).\n",
        "- El valor de dropout.\n",
        "- El número de neuronas en las capas intermedias.\n",
        "- El número de épocas de entrenamiento.\n",
        "- El tamaño de los lotes.\n",
        "\n",
        "Discuta los resultados."
      ],
      "metadata": {
        "id": "A9uINlg69OTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1)"
      ],
      "metadata": {
        "id": "hyuXv-0x29Xw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}